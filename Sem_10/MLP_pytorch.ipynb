{"cells":[{"cell_type":"markdown","metadata":{"id":"1bG0dT0bMaEr"},"source":["# Multilayer perceptron"]},{"cell_type":"markdown","metadata":{"id":"uEizUvs_Mryw"},"source":["Pytorch framework documentation [here](https://pytorch.org/)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WCP7-WYh_ro3"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","import time\n","from tqdm import tqdm\n","from keras.utils.np_utils import to_categorical \n","\n","import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{"id":"PQAKpRyGM5Vh"},"source":["## Load data - [MNIST](http://yann.lecun.com/exdb/mnist/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5GuRujLbydhy"},"outputs":[],"source":["# Load MNIST data\n","data = pd.read_csv( _ , header=None)\n","\n","X = _\n","y = _\n","\n","print (X.shape, y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7TlM7c2HTC6","outputId":"0035e567-4395-4003-93f7-f6e35af281d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["(16000, 28, 28) (4000, 28, 28) (16000,) (4000,)\n"]}],"source":["# create train / test splits\n","X_train, X_test, y_train, y_test = _\n","\n","# Reshape to bidimensional (image) size\n","X_train, X_test = _ , _ \n","\n","print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3V4KSR11Epo_"},"outputs":[],"source":["# Visualize grid of samples \n","grid_size = _ \n","\n","_, axes = plt.subplots ( _ , _ , figsize=(12,12))\n","axes = _ \n","\n","for i, ax in enumerate(axes): \n","  ax.imshow( _ , cmap='gray')\n","  ax.set_axis_off()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BIin-x7KeuRp"},"outputs":[],"source":["# Reshape the data - MLPs do not understand such '2D' stuff\n","# Reshape to 1D is similat to \"flatten\" an image\n","\n","# Configuration options\n","feature_vector_length = 784\n","num_classes = 10\n","\n","X_train = _ \n","X_test = _ \n","\n","# Convert into 0 - 1 values\n","X_train = _ \n","X_test = _ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qCT-uXQCf-R"},"outputs":[],"source":["# Convert target classes to categorical ones - one hot encoding\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)"]},{"cell_type":"markdown","metadata":{"id":"KRJ9wAEPP-nD"},"source":["## Create a graph model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J-P8HIx_Qatp"},"outputs":[],"source":["# Model params for training\n","epochs = 100\n","batch_size = 200 # We dont train the whole dataset at the time\n","losses = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yv7K_A2vPxzz"},"outputs":[],"source":["model = torch.nn.Sequential(\n","    nn.Linear( _ , _ ), nn.ReLU(),\n","    nn.Linear( _ , _ ), nn.ReLU(),\n","    nn.Linear( _ , _ ), nn.ReLU(),\n","    nn.Linear( _ , _ ), nn.ReLU(),\n","    nn.Linear( _ , _ ), nn.ReLU(),\n","    nn.Linear( _ , _ ), nn.Softmax()\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"UFACnhquRzC9"},"source":["## Define loss function and optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u82o2geoRyUY"},"outputs":[],"source":["loss = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = _ )"]},{"cell_type":"markdown","metadata":{"id":"Oo5RcYgAR3jF"},"source":["## Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wr9Nf23DSxcW"},"outputs":[],"source":["start_time = time.time()\n","\n","for _ : # Iterate over all the num of epochs\n","  #\n","  progress = _ \n","  batch_losses = 0\n","  \n","  for _ : # Iterate over all batches of data\n","    #\n","    # First step, take the data from the dataset\n","    batch_X = _ \n","    batch_y = _ \n","    batch_X = torch.from_numpy(batch_X) # Convert to torch tensor to feed the graph\n","    batch_y = torch.from_numpy(batch_y) # Convert to torch tensor to feed the graph\n","\n","    # Zero the gradients\n","    optimizer.zero_grad()\n","\n","    # Perform forward pass\n","    predictions = _\n","\n","    # Compute loss\n","    batch_loss = loss(predictions, batch_y)\n","\n","    # Perform backward pass\n","    batch_loss.backward()\n","\n","    # Optimize parameters\n","    optimizer.step()\n","\n","    ## Accumulate loss to compute mean over all batches\n","    batch_losses += batch_loss.item()\n","\n","    # Compute time and show all progress\n","    elapsed_time = time.time() - start_time\n","    progress.set_description(\"[Epoch %d/%d] [Batch %d/%d] [Loss: %f] time: %3f\" % (epoch, epochs,\n","                                                                          batch_i, len(X_train),\n","                                                                          batch_loss.item(),\n","                                                                          elapsed_time))\n","  \n","  # Save epoch loss\n","  losses.append(batch_losses/(len(X_train)/batch_size))\n","\n","  \n"]},{"cell_type":"markdown","metadata":{"id":"p8fBn5saR7BP"},"source":["## Plot results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTAUMxmfdHEx"},"outputs":[],"source":["# Plot progress (loss function)"]},{"cell_type":"markdown","metadata":{"id":"jyBi-3lER-yv"},"source":["## Compute metrics over ```X_test``` images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOv_99fEIYHB"},"outputs":[],"source":["progress = tqdm(range( _ , _ , _ ), ncols=100)\n","predictions = _\n","\n","for _ : # Iterate over all batches of data\n","  #\n","  batch_X = _ \n","  batch_y = _ \n","  \n","  # Perform forward pass to compute predictions \n","  batch_predictions = _ \n","  _  = _ \n","\n","y_test_ = np.argmax(y_test, axis=1)\n","acc = _ \n","cm_ = _ \n","\n","# Compute confusion matrix and accuracy\n","_, ax = plt.subplots(figsize=(8,5))\n","sns.heatmap(cm_, cmap=\"hot\", annot=True, ax=ax)\n","print(\"acc: {0}\".format(acc))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["1bG0dT0bMaEr","PQAKpRyGM5Vh","KRJ9wAEPP-nD","UFACnhquRzC9","Oo5RcYgAR3jF","p8fBn5saR7BP","jyBi-3lER-yv"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}