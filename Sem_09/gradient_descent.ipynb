{"cells":[{"cell_type":"markdown","metadata":{"id":"-C0TJEthCKE-"},"source":["# Gradient Descent (Lineal Regresion)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2D64lLFvaRX"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from sklearn.datasets import make_regression\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGbC0NgvoXOT"},"outputs":[],"source":["X, y = make_regression(n_samples = 500, n_features = 1 , noise = 10, random_state = 1)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n","\n","plt.scatter( _ , _ ,  c='b', s=8)\n","plt.scatter( _ , _ ,  c='r', s=8)\n","print (X_train.shape, X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvvKyH0wvR3H"},"outputs":[],"source":["def mse (y_true, y_pred):\n","  return np.square(y_true - y_pred).mean()"]},{"cell_type":"markdown","metadata":{"id":"rx63AYrU2-vr"},"source":["Useful definitions:\n","\n","$\\Large{y = mx_i + b }$ \\\\\n","\n","$J = \\Large{\\frac{1}{n} \\sum^{n}_{i=1} (y_i - mx_i + b)^2 }$ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uufcMfKzvLz_"},"outputs":[],"source":["# Parameter definition\n","epochs = 100\n","learning_rate = 0.1\n","stop_criteria = 1e-3\n","\n","# Initial values \n","m = _ \n","b = _ \n","\n","# Additional options\n","display_step = 5\n","steps = len(X_train)\n","loss = []\n","\n","# Optimization process\n","for _ :\n","    # Gradient initialization \n","    m_gradient  = 0\n","    b_gradient  = 0\n","    total_error = 0\n","\n","    # Compute error and gradients\n","    for i in range(0, _ ):\n","        #\n","        prediction = m * _ + b\n","        error = _ \n","\n","        # Compute the gradients \n","        m_gradient -= _ \n","        b_gradient -= _ \n","        total_error += error\n","    \n","    # Update params\n","    m = m - (learning_rate * _ )\n","    b = b - (learning_rate * _ )\n","    \n","    # Save average error as loss\n","    loss.append(total_error / steps)\n","    \n","    # Show everything every display_step epochs\n","    if epoch % display_step == 0: \n","        plt.scatter(X_train, y_train)\n","        # line between min-max--points\n","        pred_x = [min(X_train), max(X_train)]\n","        pred_y = [m * min(X_train) + b, m * max(X_train) + b ]\n","        plt.title('Epoch: {0}, MSE: {1}'.format(epoch, total_error / steps))\n","        plt.plot(pred_x, pred_y, \"r\")\n","        plt.show()\n","        plt.pause(1)\n","        clear_output(wait=False)\n","    \n","    # Convergence condition\n","    if max(abs(learning_rate * m_gradient), abs(learning_rate * b_gradient)) < stop_criteria:\n","        break\n","\n","\n","# ImpresiÃ³n de los resultados\n","print(\"Computed values are: \", m, b)\n","print(\"Finished in \", epoch, \" epochs \")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBjVSdMg8Dzp"},"outputs":[],"source":["pred_x = [min(X_test), max(X_test)]\n","pred_y = [m * min(X_test) + b , m * max(X_test) + b]\n","\n","\n","_, axes = plt.subplots(1,2, figsize=(12,5))\n","axes[0].scatter( _ , _ , c='r', s=8)\n","axes[0].set_title('Epoch: {0}'.format(epoch))\n","axes[0].plot( _ , _ , \"m\")\n","\n","# plotting the loss\n","axes[1].plot(range(0, len(loss)), loss), axes[1].set_title(\"Loss (MSE)\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"lIdRRMB52tRc"},"source":["## Putting everything together"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5MXoakLJjzp"},"outputs":[],"source":["class our_linear_model():\n","  def __init__(self, m = 1, b = 1, learning_rate = 0.1, stop_criteria = 1e-3):\n","    #\n","    self.m_ = _\n","    self.b_ = _ \n","    self.learning_rate = _\n","    self.stop_criteria = _\n","    self.loss = []\n","  \n","  def predict (self, x):\n","    return None\n","  \n","  def mse (self, y_true, y_pred):\n","    return np.square(y_true - y_pred).mean()\n","  \n","  def gradient_step (self):\n","    #\n","    return None \n","\n","  def fit (self, X, y, epochs = 100, display_step = 5):\n","    #\n","    steps = _ \n","    for _ :\n","      # Gradient initialization \n","      m_gradient, b_gradient, total_error = 0, 0, 0\n","\n","      # Compute error and gradients\n","      for i in range(0, _ ):\n","          #\n","          prediction = _ \n","          error = _\n","\n","          # Compute the gradients \n","          m_gradient -= (2/steps) * (y[i] - prediction) * X[i]\n","          b_gradient -= (2/steps) * (y[i] - prediction) \n","          total_error += error\n","      \n","      # Update params\n","      _\n","      \n","      # Save average error as loss\n","      self.loss.append(total_error / steps)\n","      \n","      # Show everything every display_step epochs\n","      if epoch % display_step == 0: \n","          plt.scatter(X, y)\n","          pred_x = [min(X), max(X)]\n","          pred_y = [ _ , _ ]\n","          plt.title('Epoch: {0}, MSE: {1}'.format(epoch, error))\n","          plt.plot( _ , _ , \"r\")\n","          plt.show()\n","          plt.pause(1)\n","          clear_output(wait=False)\n","      \n","      # Convergence condition\n","      if max(abs(self.learning_rate * m_gradient), abs(self.learning_rate * b_gradient)) < self.stop_criteria:\n","          break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FgDQON17DU2g"},"outputs":[],"source":["model = our_linear_model()\n","\n","model.fit (X_train, y_train)\n","\n","# Print params\n","print(\"Computed values are: \", model.m_, model.b_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITfi9vPsGzT3"},"outputs":[],"source":["pred_x = [min(X_test), max(X_test)]\n","pred_y = [model.predict(min(X_test)), model.predict(max(X_test))]\n","\n","\n","_, axes = plt.subplots(1,2, figsize=(12,5))\n","axes[0].scatter( _ , _ , c='r', s=8)\n","axes[0].plot( _ , _ , \"g\")\n","\n","\n","axes[1].plot(range(0, len(model.loss)), model.loss), axes[1].set_title(\"Loss (MSE)\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EYFNzKYd9QqU"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMnybnC1WNiaakXNEXHO1jF","collapsed_sections":["-C0TJEthCKE-","lIdRRMB52tRc"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
